{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle # save and load serialized data (dictionaries, lists...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOARD_ROWS = 3\n",
    "BOARD_COLS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self, p1, p2):\n",
    "        self.board = np.zeros([BOARD_ROWS, BOARD_COLS])\n",
    "        self.p1 = p1\n",
    "        self.p2 = p2\n",
    "        self.isEnd = False\n",
    "        self.symbol = 1\n",
    "        \n",
    "    def availablePositions(self):\n",
    "        positions = []\n",
    "        for i in range(BOARD_ROWS):\n",
    "            for j in range(BOARD_COLS):\n",
    "                if self.board[i,j] == 0:\n",
    "                    positions.append((i,j))\n",
    "        return positions\n",
    "        \n",
    "    def updateBoard(self, position):\n",
    "        self.board[position] = self.symbol\n",
    "        if self.symbol == 1:\n",
    "            self.symbol = -1\n",
    "        else:\n",
    "            self.symbol = 1\n",
    "        \n",
    "    def checkWinner(self):\n",
    "        diag_1 = 0\n",
    "        diag_2 = 0   \n",
    "        for i in range(BOARD_ROWS):\n",
    "            #have winner\n",
    "            if (sum(abs(self.board[i,:])) == BOARD_ROWS) or (sum(abs(self.board[:, i])) == BOARD_COLS):\n",
    "                self.isEnd = True\n",
    "                if sum(self.board[i,:]) == BOARD_COLS:\n",
    "                    return 1\n",
    "                elif sum(self.board[i,:]) == -BOARD_COLS:\n",
    "                    return -1\n",
    "                elif sum(self.board[:,i]) == BOARD_COLS:\n",
    "                    return 1\n",
    "                elif sum(self.board[:,i]) == -BOARD_COLS:\n",
    "                    return -1\n",
    "            diag_1 += self.board[i, i]\n",
    "            diag_2 += self.board[i, BOARD_COLS-i-1]\n",
    "        if (diag_1 == BOARD_COLS) or (diag_2 == BOARD_COLS):\n",
    "            self.isEnd = True\n",
    "            return 1\n",
    "        elif (diag_1 == -BOARD_COLS) or (diag_2 == -BOARD_COLS):\n",
    "            self.isEnd = True\n",
    "            return -1\n",
    "        \n",
    "        #tie\n",
    "        if len(self.availablePositions()) == 0:\n",
    "            self.isEnd = True\n",
    "            return 0\n",
    "        \n",
    "        #not finished\n",
    "        self.isEnd = False\n",
    "        return None\n",
    "    \n",
    "    def resetState(self):\n",
    "        self.board = np.zeros([BOARD_ROWS, BOARD_COLS])\n",
    "        self.isEnd = False\n",
    "        self.symbol = 1\n",
    "        \n",
    "    def reward(self):\n",
    "        winner = self.checkWinner()\n",
    "        if winner is not None:\n",
    "            if winner == 1:\n",
    "                self.p1.feedReward(1)\n",
    "                self.p2.feedReward(0)\n",
    "            elif winner == -1:\n",
    "                self.p1.feedReward(0)\n",
    "                self.p2.feedReward(1)\n",
    "            else:\n",
    "                self.p1.feedReward(0.1)\n",
    "                self.p2.feedReward(0.3)\n",
    "    \n",
    "    def train(self, num=10000):\n",
    "        for i in range(num):\n",
    "            if i%1000==0:\n",
    "                print('Game: {}'.format(i))\n",
    "            while not self.isEnd:\n",
    "                positions = self.availablePositions()\n",
    "                action = self.p1.chooseAction(positions, self.board, self.symbol)\n",
    "                self.updateBoard(action)\n",
    "                state = self.p1.getHash(self.board)\n",
    "                self.p1.addState(state)\n",
    "                winner = self.checkWinner()\n",
    "                if winner is not None:\n",
    "                    self.reward()\n",
    "                    self.p1.resetPlayer()\n",
    "                    self.p2.resetPlayer()\n",
    "                    self.resetState()\n",
    "                    break\n",
    "                else:\n",
    "                    positions = self.availablePositions()\n",
    "                    action = self.p2.chooseAction(positions, self.board, self.symbol)\n",
    "                    self.updateBoard(action)\n",
    "                    state = self.p1.getHash(self.board)\n",
    "                    self.p2.addState(state)\n",
    "                    winner = self.checkWinner()\n",
    "                    if winner is not None:\n",
    "                        self.reward()\n",
    "                        self.p1.resetPlayer()\n",
    "                        self.p2.resetPlayer()\n",
    "                        self.resetState()\n",
    "                        break\n",
    "                        \n",
    "    def playHuman(self):\n",
    "        while not self.isEnd:\n",
    "            positions = self.availablePositions()\n",
    "            p1_action = self.p1.chooseAction(positions, self.board, self.symbol)\n",
    "            self.updateBoard(p1_action)\n",
    "            self.showBoard()\n",
    "            win = self.checkWinner()\n",
    "            if win is not None:\n",
    "                if win == 1:\n",
    "                    print(self.p1.name + ' wins!')\n",
    "                elif win == -1:\n",
    "                    print(self.p2.name + ' wins!')\n",
    "                else:\n",
    "                    print('Tie!')\n",
    "                self.resetState()\n",
    "                break\n",
    "            else:\n",
    "                positions = self.availablePositions()\n",
    "                p2_action = self.p2.chooseAction(positions)              \n",
    "                self.updateBoard(p2_action)\n",
    "                self.showBoard()\n",
    "                win = self.checkWinner()\n",
    "                if win is not None:\n",
    "                    if win == 1:\n",
    "                        print(self.p1.name + ' wins!')\n",
    "                    elif win == -1:\n",
    "                        print(self.p2.name + ' wins!')\n",
    "                    else:\n",
    "                        print('Tie!')\n",
    "                    self.resetState()\n",
    "                    break\n",
    "                    \n",
    "    def playRandom(self, num=1000):\n",
    "        p1 = 0\n",
    "        p2 = 0\n",
    "        for i in range(num):\n",
    "            while not self.isEnd:\n",
    "                positions = self.availablePositions()\n",
    "                p1_action = self.p1.chooseAction(positions, self.board, self.symbol)\n",
    "                self.updateBoard(p1_action)\n",
    "                win = self.checkWinner()\n",
    "                if win is not None:\n",
    "                    if win == 1:\n",
    "                        p1 += 1\n",
    "                    elif win == -1:\n",
    "                        p2 += 1\n",
    "                    self.resetState()\n",
    "                    break\n",
    "                else:\n",
    "                    positions = self.availablePositions()\n",
    "                    p2_action = self.p2.chooseAction(positions)              \n",
    "                    self.updateBoard(p2_action)\n",
    "                    win = self.checkWinner()\n",
    "                    if win is not None:\n",
    "                        if win == 1:\n",
    "                            p1 += 1\n",
    "                        elif win == -1:\n",
    "                            p2 += 1                    \n",
    "                        self.resetState()\n",
    "                        break\n",
    "        print('Trained agent({}) won: {} out of {}'.format(self.p1.name, p1, num))\n",
    "        print('Untrained agent({}) won: {} out of {}'.format(self.p2.name, p2, num))\n",
    "        print('Ties: {} out of {}'.format(num - p1 - p2, num))\n",
    "        print('------------------------------------------')\n",
    "                    \n",
    "                \n",
    "    def showBoard(self):\n",
    "        # p1: x  p2: o\n",
    "        for i in range(0, BOARD_ROWS):\n",
    "            print('-------------')\n",
    "            out = '| '\n",
    "            for j in range(0, BOARD_COLS):\n",
    "                if self.board[i, j] == 1:\n",
    "                    token = 'x'\n",
    "                if self.board[i, j] == -1:\n",
    "                    token = 'o'\n",
    "                if self.board[i, j] == 0:\n",
    "                    token = ' '\n",
    "                out += token + ' | '\n",
    "            print(out)\n",
    "        print('-------------')\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def __init__(self, name, num = 10000,exploration_rate=0.2):\n",
    "        self.name = name\n",
    "        self.exp_rate = exploration_rate\n",
    "        self.lr = 0.5\n",
    "        self.gamma = 0.9\n",
    "        self.states_value = {}\n",
    "        self.states = []\n",
    "        self.num_games = num\n",
    "        \n",
    "    def getHash(self, board):\n",
    "        return str(board.reshape(board.size))\n",
    "        \n",
    "    def chooseAction(self, positions, board, symbol):\n",
    "        if np.random.uniform(0,1) <= self.exp_rate:\n",
    "            action = positions[np.random.choice(len(positions))]\n",
    "        else:\n",
    "            max_value = -999\n",
    "            for p in positions:\n",
    "                new_board = board.copy()\n",
    "                new_board[p] = symbol\n",
    "                new_board_hash = self.getHash(new_board)\n",
    "                if self.states_value.get(new_board_hash) is None:\n",
    "                    value = 0\n",
    "                else:\n",
    "                    value = self.states_value.get(new_board_hash)\n",
    "                if max_value <= value:\n",
    "                    max_value = value\n",
    "                    action = p\n",
    "        return action\n",
    "    \n",
    "    def addState(self, state):\n",
    "        self.states.append(state)\n",
    "    \n",
    "    def feedReward(self, reward):\n",
    "        for state in reversed(self.states):\n",
    "            if self.states_value.get(state) is None:\n",
    "                self.states_value[state] = 0\n",
    "            self.states_value[state] += self.lr*(self.gamma*reward - self.states_value[state])\n",
    "            reward = self.states_value[state]\n",
    "            \n",
    "    def resetPlayer(self):\n",
    "        self.states = []     \n",
    "        \n",
    "    def savePolicy(self, num):\n",
    "        fw = open('policy_' + str(self.name) + '_' + str(num), 'wb')\n",
    "        pickle.dump(self.states_value, fw)\n",
    "        fw.close()\n",
    "\n",
    "    def loadPolicy(self, file):\n",
    "        fr = open(file, 'rb')\n",
    "        self.states_value = pickle.load(fr)\n",
    "        fr.close()    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Human:\n",
    "    def __init__(self, name='human'):\n",
    "        self.name = name\n",
    "    \n",
    "    def chooseAction(self, positions):\n",
    "        print('Input row number: ')\n",
    "        row = int(input())\n",
    "        print('Input col number: ')\n",
    "        col = int(input())\n",
    "        action = (row, col)\n",
    "        if action in positions:\n",
    "            return action\n",
    "        else:\n",
    "            print('Invalid selected position.')\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UntrainedAgent:\n",
    "    def __init__(self, name='untrained'):\n",
    "        self.name = name\n",
    "    \n",
    "    def chooseAction(self, positions):\n",
    "        action = positions[np.random.choice(len(positions))]\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game: 0\n",
      "Game: 1000\n",
      "Game: 2000\n",
      "Game: 3000\n",
      "Game: 4000\n",
      "Game: 5000\n",
      "Game: 6000\n",
      "Game: 7000\n",
      "Game: 8000\n",
      "Game: 9000\n",
      "Game: 0\n",
      "Game: 1000\n",
      "Game: 2000\n",
      "Game: 3000\n",
      "Game: 4000\n",
      "Game: 5000\n",
      "Game: 6000\n",
      "Game: 7000\n",
      "Game: 8000\n",
      "Game: 9000\n",
      "Game: 10000\n",
      "Game: 11000\n",
      "Game: 12000\n",
      "Game: 13000\n",
      "Game: 14000\n",
      "Game: 15000\n",
      "Game: 16000\n",
      "Game: 17000\n",
      "Game: 18000\n",
      "Game: 19000\n",
      "Game: 0\n",
      "Game: 1000\n",
      "Game: 2000\n",
      "Game: 3000\n",
      "Game: 4000\n",
      "Game: 5000\n",
      "Game: 6000\n",
      "Game: 7000\n",
      "Game: 8000\n",
      "Game: 9000\n",
      "Game: 10000\n",
      "Game: 11000\n",
      "Game: 12000\n",
      "Game: 13000\n",
      "Game: 14000\n",
      "Game: 15000\n",
      "Game: 16000\n",
      "Game: 17000\n",
      "Game: 18000\n",
      "Game: 19000\n",
      "Game: 20000\n",
      "Game: 21000\n",
      "Game: 22000\n",
      "Game: 23000\n",
      "Game: 24000\n",
      "Game: 25000\n",
      "Game: 26000\n",
      "Game: 27000\n",
      "Game: 28000\n",
      "Game: 29000\n",
      "Game: 30000\n",
      "Game: 31000\n",
      "Game: 32000\n",
      "Game: 33000\n",
      "Game: 34000\n",
      "Game: 35000\n",
      "Game: 36000\n",
      "Game: 37000\n",
      "Game: 38000\n",
      "Game: 39000\n",
      "Game: 40000\n",
      "Game: 41000\n",
      "Game: 42000\n",
      "Game: 43000\n",
      "Game: 44000\n",
      "Game: 45000\n",
      "Game: 46000\n",
      "Game: 47000\n",
      "Game: 48000\n",
      "Game: 49000\n",
      "Game: 0\n",
      "Game: 1000\n",
      "Game: 2000\n",
      "Game: 3000\n",
      "Game: 4000\n",
      "Game: 5000\n",
      "Game: 6000\n",
      "Game: 7000\n",
      "Game: 8000\n",
      "Game: 9000\n",
      "Game: 10000\n",
      "Game: 11000\n",
      "Game: 12000\n",
      "Game: 13000\n",
      "Game: 14000\n",
      "Game: 15000\n",
      "Game: 16000\n",
      "Game: 17000\n",
      "Game: 18000\n",
      "Game: 19000\n",
      "Game: 20000\n",
      "Game: 21000\n",
      "Game: 22000\n",
      "Game: 23000\n",
      "Game: 24000\n",
      "Game: 25000\n",
      "Game: 26000\n",
      "Game: 27000\n",
      "Game: 28000\n",
      "Game: 29000\n",
      "Game: 30000\n",
      "Game: 31000\n",
      "Game: 32000\n",
      "Game: 33000\n",
      "Game: 34000\n",
      "Game: 35000\n",
      "Game: 36000\n",
      "Game: 37000\n",
      "Game: 38000\n",
      "Game: 39000\n",
      "Game: 40000\n",
      "Game: 41000\n",
      "Game: 42000\n",
      "Game: 43000\n",
      "Game: 44000\n",
      "Game: 45000\n",
      "Game: 46000\n",
      "Game: 47000\n",
      "Game: 48000\n",
      "Game: 49000\n",
      "Game: 50000\n",
      "Game: 51000\n",
      "Game: 52000\n",
      "Game: 53000\n",
      "Game: 54000\n",
      "Game: 55000\n",
      "Game: 56000\n",
      "Game: 57000\n",
      "Game: 58000\n",
      "Game: 59000\n",
      "Game: 60000\n",
      "Game: 61000\n",
      "Game: 62000\n",
      "Game: 63000\n",
      "Game: 64000\n",
      "Game: 65000\n",
      "Game: 66000\n",
      "Game: 67000\n",
      "Game: 68000\n",
      "Game: 69000\n",
      "Game: 70000\n",
      "Game: 71000\n",
      "Game: 72000\n",
      "Game: 73000\n",
      "Game: 74000\n",
      "Game: 75000\n",
      "Game: 76000\n",
      "Game: 77000\n",
      "Game: 78000\n",
      "Game: 79000\n",
      "Game: 80000\n",
      "Game: 81000\n",
      "Game: 82000\n",
      "Game: 83000\n",
      "Game: 84000\n",
      "Game: 85000\n",
      "Game: 86000\n",
      "Game: 87000\n",
      "Game: 88000\n",
      "Game: 89000\n",
      "Game: 90000\n",
      "Game: 91000\n",
      "Game: 92000\n",
      "Game: 93000\n",
      "Game: 94000\n",
      "Game: 95000\n",
      "Game: 96000\n",
      "Game: 97000\n",
      "Game: 98000\n",
      "Game: 99000\n"
     ]
    }
   ],
   "source": [
    "#TRAINING\n",
    "episodes = [10000,20000,50000,100000]\n",
    "for episode in episodes:\n",
    "    p1 = Player('player_1')\n",
    "    p2 = Player('player_2')\n",
    "\n",
    "    #training\n",
    "    state = State(p1, p2)\n",
    "    state.train(episode)\n",
    "    #save policies\n",
    "    p1.savePolicy(episode)\n",
    "    p2.savePolicy(episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of episodes trained: 10000\n",
      "Trained agent(computer) won: 997 out of 1000\n",
      "Untrained agent(untrained) won: 0 out of 1000\n",
      "Ties: 3 out of 1000\n",
      "------------------------------------------\n",
      "Number of episodes trained: 20000\n",
      "Trained agent(computer) won: 906 out of 1000\n",
      "Untrained agent(untrained) won: 42 out of 1000\n",
      "Ties: 52 out of 1000\n",
      "------------------------------------------\n",
      "Number of episodes trained: 50000\n",
      "Trained agent(computer) won: 962 out of 1000\n",
      "Untrained agent(untrained) won: 3 out of 1000\n",
      "Ties: 35 out of 1000\n",
      "------------------------------------------\n",
      "Number of episodes trained: 100000\n",
      "Trained agent(computer) won: 952 out of 1000\n",
      "Untrained agent(untrained) won: 7 out of 1000\n",
      "Ties: 41 out of 1000\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#TESTING\n",
    "for episode in episodes:\n",
    "    p1 = Player('computer', exploration_rate=0)\n",
    "    p1.loadPolicy('policy_player_1_' + str(episode))\n",
    "\n",
    "    p2 = UntrainedAgent('untrained')\n",
    "\n",
    "    state = State(p1, p2)\n",
    "    print('Number of episodes trained: {}'.format(episode))\n",
    "    state.playRandom(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "Input row number: \n",
      "1\n",
      "Input col number: \n",
      "1\n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   | o |   | \n",
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "Input row number: \n",
      "0\n",
      "Input col number: \n",
      "2\n",
      "-------------\n",
      "|   |   | o | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "-------------\n",
      "|   |   | o | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "| x |   | x | \n",
      "-------------\n",
      "Input row number: \n",
      "2\n",
      "Input col number: \n",
      "1\n",
      "-------------\n",
      "|   |   | o | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "| x | o | x | \n",
      "-------------\n",
      "-------------\n",
      "|   | x | o | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "| x | o | x | \n",
      "-------------\n",
      "Input row number: \n",
      "0\n",
      "Input col number: \n",
      "0\n",
      "-------------\n",
      "| o | x | o | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "| x | o | x | \n",
      "-------------\n",
      "-------------\n",
      "| o | x | o | \n",
      "-------------\n",
      "| x | o | x | \n",
      "-------------\n",
      "| x | o | x | \n",
      "-------------\n",
      "Tie!\n"
     ]
    }
   ],
   "source": [
    "#PLAY HUMAN\n",
    "#load trained agent\n",
    "p1 = Player('computer', exploration_rate=0)\n",
    "p1.loadPolicy('policy_player_1_' + str(10000))\n",
    "\n",
    "#human\n",
    "p2 = Human('human')\n",
    "\n",
    "state = State(p1, p2)\n",
    "state.playHuman()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
